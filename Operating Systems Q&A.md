Operating Systems Q&A

## 内核

### 进程进入内核的三种方式？

1. 系统调用
2. 异常：缺页异常、div_zero...
3. 中断：时钟中断、硬盘中断...



## 线程&进程

### 内核级线程切换的时候，上下文保存在哪里？都保存了哪些信息？

A: Intel为每个线程提供了一个`TSS(Task State Segment)`任务状态段，每个线程在切换之前会将自己的寄存器组的信息存入这个TSS段中，TSS既然是段，就可以从GDT表中找到它。我们从GDT表中找到欲切换线程的TSS段，将这个线程的运行现场从这个线程的TSS段中恢复到寄存器中来完成上下文的切换。

但是大多是现代操作系统基本上都不用TSS段来完成线程切换了，这是因为在线程切换时使用的指令ljmp通常要花费200个时钟周期，很费时间。取而代之的是使用内核栈来保存运行时信息。current指针指向了当前运行线程的TCB块，TCB中存储了当前线程的内核栈的基地址，然后各种寄存器入栈。

入栈顺序：

SS  ESP  EFLAGS  CS  EIP  这部分是原线程的代码段和栈段的信息

DS  ES  FS  GS  ESI  EDI  EDX 这部分做完以后就可以执行

```assembly
movl $x010, %edx
mov %dx, %ds
mov %dx, %es
```

来将段寄存器DS, ES设置为内核数据段选择子，这样以后就可以访问内内核数据了

EBP  ECX  EBX  EAX  这部分是另外一些常用寄存器

总而言之，现代操作系统将上下文保存在内核栈中，这是在内核栈切换的时候将寄存器压栈来完成的，相应的，从内核栈返回到用户栈的时候执行的就是这些操作的逆，即将这些寄存器反序弹栈。保存的信息为寄存器组。



### Linux中进程栈和内核栈的区别？

A: 事实上，Linux系统中是没有进程和线程之分的。Linux中的进程调度，可以理解为，调度的是一系列执行任务列表（线程）。所以只有线程有自己的用户栈和内核栈，进程只是改变了自己的线程的映射的物理地址。



### 进程和线程的区别？

![image-20201013115054645](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201013115054645.png)

![image-20201013115108390](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201013115108390.png)

### 单线程进程和多线程进程的区别？

![image-20201013115322414](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201013115322414.png)

![image-20201013115737124](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201013115737124.png)



### 线程相比进程的好处有哪些？

创建和终结一个线程需要的时间更少、线程间切换比进程间切换要快得多、线程之间有着同样的读写优先级，访问文件和内存时无需相互通信，不用陷入内核态（同步更容易）。



### 当一个进程中的线程阻塞时，它会阻塞整个进程吗？



### 用户级线程相比内核级线程的好处？

线程切换不需要进入内核态，因为所有的线程管理块TCB都在这个进程的用户空间中，可以从中取出执行现场直接恢复；而内核级线程把执行现场保存在了内核栈中，想要切换线程必须要进入内核、用户程序有权自己调度线程，通常这些程序的线程调度都是application-specific的、用户级线程可以在任何操作系统上工作，比如JVM。



### 用户级线程相比内核级线程的缺点？

当一个进程中的某个用户级线程执行系统调用然后被阻塞，整个进程里的所有线程都将被阻塞，因为操作系统并不知道这些用户级线程的存在，会把它们当作一个线程来对待、用户级线程无法利用多处理器。

#### 如何解决第一个问题？

 写一个多进程的程序而不是多线程，比如Chrome. 但是这么做也会增加很多开销。



## 进程同步

### 什么是死锁？

死锁是多个进程在互相等待对方向前执行而造成的谁也无法向前执行的僵局



### 死锁产生的必要条件？如何预防？

- 互斥(Mutex)：资源不能被共享，一个资源每次只能被一个进程使用 --> 资源本身的特性
- 不可剥夺(holding relationship)：进程已获得的资源，在未使用完之前，不能强行剥夺 --> 系统不可剥夺进程的资源
- 占有且等待(hold-and-wait)：一个进程因请求资源而阻塞时，对已获得的资源保持不放 --> 进程本身的行为
- 循环等待(circular waiting)：若干进程之间形成一种头尾相接的循环性资源等待关系

一旦能够破坏这四个必要条件中的某个条件，就不会形成死锁，这就是死锁**预防**的基本想法

在这四个必要条件中，互斥是许多资源自身的基本特性，无法改变，比如打印机资源无法被共享

不可剥夺是程序本身决定的，很多资源如果不是程序执行到一定的时候主动去释放，是不可以被强行剥夺的

至于请求与保持，显然不能要求进程不去请求任何资源，这样它就没法往下执行了，所以只能从不保持下手：

进程可以一次性地申请到自己所需的全部资源

解决循环等待的方法是资源按序申请。即为每个资源进行编号，进程对资源的申请必须按照编号从小到大（或从大到小）的顺序进行申请。只要资源按序申请就一定不会造成死锁，这是因为此时的资源分配图中一定不会出现环路。如果出现了环路，就一定存在一个进程其持有资源的编号大于其请求资源的编号。



死锁的预防需要花费的代价太大，不采用以上办法。



### 系统资源分配图

是一个有向图，有两类节点：进程集合 & 资源集合

进程集合P = {P1, P2, ..., Pn}

资源集合R = {R1, R2, ..., Rn}

图中所有的边都是进程和资源节点之间的边

由进程节点指向资源节点是请求边

由资源节点指向进程节点是分配边



由资源分配图表示的一个死锁的案例：

![image-20201029140442731](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201029140442731.png)



![image-20201029140531324](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201029140531324.png)



如果资源分配图中不含有回路的话，则一定不存在死锁

如果资源分配图中含有回路的话，则死锁**可能**存在：如果每个资源类型有多个实例的话，存在回路不意味着死锁已经发生



![image-20201029140850078](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201029140850078.png)



P1等待的资源是R1，而R1既可以由P2释放，也可以由P3释放

图中P2将资源R1的一个实例释放后，P1和P3都可以向前推进



### 如何避免死锁？

基本思想：每次资源申请都要判断是否有出现死锁的风险，如果有风险就拒绝此次申请

**银行家算法**是用来完成这一判断的算法

抽象：在银行中，客户要向银行申请贷款，每个客户在第一次申请贷款时会声明完成项目所需的资金量，客户会**分期贷款**。只有客户贷到了所需的全部资金才能完成项目，也才能向银行归还其全部贷款。银行要考虑的关键问题就是如何处理这些贷款请求，既保证银行有钱给客户放款，同时又保证所有客户的的总贷款要求得到满足，最终能偿还其全部贷款，这样银行才不会有损失

安全序列：P1, P2, ..., Pn 让所有进程都能顺利完成的进程序列

Allocation: OS已分配给进程的资源

Max: 进程需要的全部资源

Available: 操作系统持有的资源

操作系统需要查看各个进程的Allocation和Max和Available，看看将Available中剩下的资源分配给哪个进程才能使得Allocation达到Max，这样这个进程持有的资源就可以被释放，Available中的资源数就会变多

基于银行家算法的死锁避免是**保守**的



### 鸵鸟算法

鸵鸟算法就是忽略死锁的存在，其前提是在一个操作系统中死锁很少发生，且发生后很难检测，当死锁不幸发生时，用户需要重启电脑。



### 为什么大多数当代操作系统采用鸵鸟算法？

Unix和Windows系统都采用的是这种算法，这是因为无论是死锁的预防、避免还是恢复，对于操作系统都是不小的负担，而相比之下死锁其实很少发生。操作系统采用这种算法其实是一种折中的选择。



### 死锁检测算法

死锁检测算法类似于反向的银行家算法，区别在于银行家算法是悲观的，而死锁检测算法是乐观的，其核心思想在于只要某个进程所请求的资源小于或等于当前可以回收的资源，就认为这个进程没有死锁

![image-20201029153712862](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201029153712862.png)

![image-20201029153721444](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201029153721444.png)



问题：何时运行死锁检测算法？

每次检测 /  每k分钟检测 / 只有当CPU利用率降低到一定程度的时候才检测



## 进程间通信

### 进程间有哪些通信方式？

1. 管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
2. 命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
3. 消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
4. 共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
5. 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
6. 套接字Socket：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。
7. 信号signal ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。



### 临界区问题的三个原则？

1. Mutual Exclution 互斥访问
2. Progress 有空让进
3. Bounded waiting 有限等待



### 信号量的三种操作？

1. initialize

2. wait: semaphore--

   如果semaphore小于0，则将自己阻塞

3. signal: semaphore++

   如果semaphore之前为负数，说明阻塞队列里面有阻塞进程在等待，则唤醒阻塞队列里面的一个进程

注意：对于信号量的操作都是原子操作，也即信号量自身是临界资源，对于信号量的修改需要在临界区里进行



### 强信号量和弱信号量？

强信号量使得阻塞队列里面阻塞最久的进程被唤醒

弱信号量不指定唤醒哪个进程



## 内存

### 段选择子结构？

段选择子有16bit，其中0, 1位表示RPL，以什么样的权限去访问段；第2位为TI位，TI = 0时表示要查找GDT, TI = 1时表示要查找LDT。第三位并不用作索引，高12位用GDT或LDT表中的索引。因为段描述符的大小是8字节，所以每两个段描述符之间都相差8个字节，所以最后三位无需用作索引。



### 一个程序（进程）是如何分段的？

每个进程分为代码段、数据段和栈段。它们分别通过CS : EIP / DS : ESI / SS : ESP在GDT / LDT中找到。



### 如何找到GDT?

GDT由GDTR寄存器中储存的物理地址找到，GDTR的值是操作系统引导过程中进行初始化的，此后便一直指向GDTR不再改变。



### 什么是程序重定位？有哪些重定位的方式？

每个程序都有自己的虚拟地址空间，但这个虚拟的地址空间并不真正对应着实际的物理内存，因为不同程序的虚拟地址空间可能会有冲突，比如都想要访问0x40处，为了解决这个问题，程序在访问虚拟地址空间里的0x40的时候要加上自己物理地址段或页的基址，这就是程序重定位。有编译时重定位、载入时重定位、运行时重定位。我们通常采用运行时重定位，即每条指令执行的时候才去寻找其物理地址，这样进程就可以在内存中随意移动（换入换出）了。这个重定位的过程是由硬件(MMU)来完成的。

#### 有多个进程的时候如何重定位呢？

系统中有多个进程，每个进程被载入到不同的物理内存区域中，相应地产生了多个基址。MMU进行重定位的CPU寄存器只能有一个，应该怎么办？每个进程的重定位基址都要存放在其PCB中（事实上，是从PCB中的CS, DS, SS来分别找到该进程对应的LDT中储存的该进程的代码段，数据段和栈段的基地址。所以进程对应的三个基地址是通过查LDT表来推断出来的），然后将这个基地址取出来赋值给CPU寄存器。

#### 如何找到进程对应的LDT？

进程的LDT由LDTR寄存器找到，与指向物理地址的GDTR寄存器不同，LDTR是一个段选择子。通过LDTR在GDT中找到该LDT段对应的位置。



### 操作系统中有两个进程，描述陷入内核时并切换到另外一个进程的细节？

假设在执行进程1的时候，出现了一个中断，比如是系统调用引起的中断。操作系统通过中断符描述表(IDT)找到相应的中断处理函数入口，即从IDT表项中取出段号信息赋给CS，从IDT表项中取出段内偏移信息赋给EIP。当初初始化IDT的时候，IDT表项中存放的段号信息就是0x08，所以在中断进入内核后，CS寄存器的值就一直是0x08了，它访问的是GDT表中的第1个表项，RPL为0表示已经进入了内核态。在操作系统内核代码执行完成后，要从系统内核返回到用户态，此时操作系统要决定是否要重新调度，现在假定要调度到进程2去执行，操作系统找到了进程2的PCB，从中找到了进程2的LDT表，进程间上下文切换中有一项重要工作就是让CPU中的寄存器LDTR指向下一个进程的LDT表的开始位置。所以此时切换到进程2以后，LDTR就指向进程2的LDT表。上下文切换还要完成内核栈的切换，并用iret指令完成用户栈和用户程序PC指针的切换，具体来说就是用iret指令从进程2的内核栈中取出CS : EIP和SS : ESP赋给CPU寄存器。进程2的内核栈中存放的CS信息一定是0x0f。所以完成切换以后CS = 0x0f，以后执行的就是用户态的代码了。



### 内存为什么要分页？

内存分页是为了更好的利用内存。如果内存不分页的话，则可能会产生较多的内存碎片。比如说，现在内存里有两块空闲内存，一块大小为150KB，另一块大小为50KB，现在我们想要放入160KB到内存里。虽然空闲内存的总大小是能够容纳下这个160KB的，但如果连续的放入的话，两块中的每一块都不能胜任这个任务。如何解决这个问题？一种可能的方案是内存压缩，即将已使用的内存放在一起，这样就可以留出200KB的空间了；另一种方案就是内存分页，其本质是内存离散化，即将内存分割成固定大小的小片。内存请求到达时，根据请求尺寸计算出总共需要的小片个数，然后在内存中任意位置找出同样数量的小片分配给内存请求。这样就解决了内存碎片问题。



### 为什么要使用多级页表？

通常的操作系统都将页面尺寸设置为4KB。如果页面尺寸较小，页表就会较大。以32位程序为例，其使用的逻辑地址是32位的，所以最大的逻辑地址是2^32，每个页面的大小为4K(2^12)，因此32位逻辑地址空间总共包含2^20个逻辑页，对应着相同数目的页表项。因此总共有2^20 = 1M个页表项。如果每个页表项用4B来表示信息，那么计算机中的**每个**进程都将需要4MB大小的内存来管理页映射关系，这将是一个相当大的开销（对于64位系统来说保存全部页的页表则变得完全不现实）。事实上，虽然每个程序都有自己的4GB虚拟地址空间，但是这4GB里面有很多空间都没有被用到，甚至可能只用了其中很小的一部分。使用两级页表，第一级页表为页目录表，其指向实际上被使用的**一块**内存的页表，页表中每个页表项指向一页内存。通常，每个页目录包含2^10个页表项，因此4MB区域是一章，其中的每个4KB是章中的节。如果某些逻辑内存区域，比如8MB~12MB区域内没有被映射到物理内存中，我们就不需要将这个页目录下的1024个页表项存放在内存中。



###  什么是快表(TLB)？它是怎么工作的？

TLB(translation lookaside buffer)本质上是页表的一个缓冲区，如果没有这个缓冲区的话，则每次访存都需要先访问页目录表，再访问页目录表指向的页表，最后由页表访问实际的物理内存，这个过程增加了许多内存访问的过程。我们的任务是访问内存，但为了访问内存却需要多访问内存一次，这是比较大的时间开销。有了TLB，我们在访问页的时候会先查看其在TLB中是否存在，TLB中不存在的话再去访问页目录表和页表。TLB中存有Valid标志位、标记和物理页号，通常采用全相联或组相联的映射方式。其中标记字段(Tag)用来表示该表项取自页表中哪个虚拟页对应的页表项。因此，TLB标记字段的内容在全相联方式下就是该表项对应的虚拟页号；组相联方式下则是对应虚拟页号的高位部分，而虚拟页号的低位部分作为TLB索引用于选择TLB组。



### 段页式内存管理的细节？





## 调度

### 什么是长程调度、中程调度和短程调度？



### 在什么情况下会发生进程调度？

1. 当前进程进入了阻塞态
2. 当前进程终止
3. 发生外部中断
4. 某个进程解除了阻塞，如果这个进程的优先级比较高，可能会将当前进程换下



### 抢占式调度和非抢占式调度的区别？

如果进程调度只发生在上面的1和2情况下，则是非抢占式调度；否则是抢占式调度

NOTE: Most modern OS adapts preemptive dicision mode (Such as Windows & Mac OS)



抢占式调度会带来比较多的额外开销，带它会提供更好的服务，防止某个进程垄断CPU的使用权



### 为什么要采用动态优先级？

因为采用静态优先级会使得低优先级的进程饿死，所以系统需要动态地修改进程的优先级



### 周转时间(Turnaround time, TAT)

`周转时间 = 等待时间 + 服务时间`

周转时间长不代表服务质量不好，周转时间短也不代表接受服务的时间就长。我们需要考察其中等待时间和服务时间的比例


#### 归一化周转时间：

`归一化周转时间 = 周转时间 / 服务时间`

其最小值为1



### 常用的进程调度算法

- 先来先服务(First-Come-First-Served, FCFS). 当一个进程停止执行时，调度器会严格选择队首进程进行执行。

  - 长进程更加偏爱FCFS：这是因为长进程可以忍耐更长的等待，相反FCFS策略会严重影响短进程的归一化周转时间
  - IO密集型进程不适合FCFS调度策略：因为FCFS会导致处理器**和**IO设备的低效
  - 在单处理器系统上FCFS并不是一种有效的调度策略，但在多处理器系统上，FCFS和优先级结合后会起到比较好的效果

- 轮转调度(Round-Robin, RR). 即时间分片技术，每个进程用完自己的时间片之后便会被放入就绪队列等待下一次调度

  - 时间片的长度是RR算法设计非常重要的一部分
  - RR算法通常用于交互式系统，而对批处理系统则毫无帮助
  - 从CPU资源的分配来讲，RR算法对于IO密集型进程是不公平的。e.g. 某个进程开始执行后执行IO操作，然后就被放入了就绪队列的**尾部**，从而这样的进程可以得到的CPU资源相对CPU密集型进程会很小，因为其根本用不完自己的时间片

- 虚拟轮转调度(Virtual-Round-Robin, VRR). 是对RR的一种优化

  - 引入了一个FCFS辅助队列(FCFS Auxiliary Queue)，假如某个进程因为IO而被阻塞，没有用完自己的时间片，那么会被放入这个优先级比较高的辅助队列

  ![image-20201105143849373](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201105143849373.png)

- 最短进程优先(Shortest-Process-Next, SPN) --> 非抢占式版本

  - 期望执行时间最短的进程将会在下次执行
  - 仍然没有解决FCFS对于长进程的偏好
  - 如果所有进程在同一时刻到达，那么SPN算法将会是最优的

- 最短进程优先(Shortest-Process-Next, SPN) --> 抢占式版本

  - 假如某个进程已经执行到一半了，这时新来了一个进程，如果这个新进程的期望执行时间小于当前进程的剩余时间，那么抢占将会发生
  - 完全消除了FCFS对于长进程的偏好
  - 和RR算法相比，并没有产生额外的中断，大幅降低了中断带来的开销
  - 开销：必须记录当前进程已经运行的时间
  - 当一个短进程进入就绪队列后，其等待时间不会超过自身的期望执行时间
  - 长进程可能会饥饿

- 最高响应比优先(Highest-Response-Ratio-Next, HRRN)

  - 这是一种非抢占式的策略

  - 当当前进程执行完成或阻塞，选择下一个具有最大R值的进程进行执行

  - `R = (w + s) / s`

    - R = response ratio
    - w = time spent waiting for the processor
    - s = expected service time

    R值其实就是归一化周转时间

  - 考虑了进程的年龄，即等待时间，等待时间越长，优先级越高

  - 尽管更加偏爱短进程，但一个长进程的优先级只要等待时间足够长，其优先级仍能够超过刚进入就绪队列的短进程

  - 解决了饥饿的问题

  - 问题：期望服务时间必须能够估计时间，这个值该如何计算？操作系统其实并不知道其具体要执行多长时间

    - 进程期望执行时间的估计

      由之前的所有进程的执行时间 --> 这个进程可能的执行时间

      方法：算数平均、指数加权平均

- 多层队列调度(Multilevel-Queue-Scheduling, MQS)

  - 为了避免计算进程期望执行时间而引入
  - 不同队列中的进程采取不同的调度算法和优先级，通常前台进程的优先级比后台进程的优先级
  - 优先级是静态的，每个进程有一个固定的优先级，每个队列的优先级也是静态的

- 反馈队列(Feedback-Scheduling, FS)

  - 每个进程刚刚进入时，其被分配到优先级最高的`RQ0`队列，在其完成第一次执行后，会被降级到RQ1队列，以此类推
  - 无需提供进程期望执行的时间，而是“惩罚”那些已经运行了比较久的进程，即那些处于优先级比较低的队列中的进程；而如果某个进程很短，其不会有机会降到低优先级队列中
  - 关注的是某个进程已经执行了多长时间，而不是试图估计某个进程还可能剩余多长时间
  - 最简单的实现：RR + FS，以周期性的间隔进行抢占
  - 一个变种：处于`RQi`队列中的进程每隔`2^i`时间发生一次轮转
  - 无论是上述的哪种具体实现，对于长进程来讲都是有可能发生饥饿的，即当系统中不停地进入大量短进程，如何解决？
  - 进程的优先级并不是只会往下降，当一个进程在某个队列中等待了足够久后，其会上升到上一个优先级队列



#### 总结

![image-20201105154155886](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201105154155886.png)







