# 应用层

## 为什么DNS基于UDP而不是TCP？

首先，DNS服务器通常很稳定，且DNS查询和应答报文的长度通常很短，所以出现丢包和数据出错的概率很小，使用UDP即可。其次，TCP的三握四挥非常耗时间，如果只是一次查询还好，但如果本地DNS服务器没有想要查询的域名的话，还需要更进一步的递归查询或者迭代查询，这每一次TCP连接的握手都是很大的时间开销，得不偿失。最后，就算DNS解析出错了，刷新下页面重新提交解析请求就好，数据出错造成的损失很小。

事实上，DNS解析既可以使用UDP，也可以使用TCP，只不过通常使用UDP而已。



## 在浏览器中输入URL后发生了什么

### DNS域名解析

首先，浏览器会对一些默认的东西自动进行补齐。例如：互联网URL默认端口号为80、浏览器还会默认补齐协议http和www

DNS解析分为以下几个步骤：

1. 首先查看浏览器dns缓存中是否有域名对应的ip
2. 如果没有，则查看操作系统dns缓存中是否有对应的ip
3. 如果还没有就对本地区的dns服务器发起请求
4. 如果还没有，就到根服务器请求解析

迭代查询 OR 递归查询

根服务器 --> 顶级域名服务器 --> 权威域名服务器

一般本地DNS地址由ISP通过DHCP协议动态分配，我们仍可以手动把它修改为公共DNS，比如Google提供的8.8.8.8和国内的114.114.114.114

有时候DNS解析的结果里面包含了许多不同的ip地址，这是为了负载均衡

### 建立TCP连接

三次握手

### 发送HTTP请求

浏览器会对请求进行包装，包装成请求报文

### 服务器处理请求

服务器收到请求报文后会对请求报文进行处理，执行接口对应的代码，处理完成后响应客户端。由于http是无状态的，正常情况下，客户端收到响应后就会直接断开连接，然后一次http事务就完成了

### 返回响应结果

### 关闭TCP连接

四次挥手，双方各自表示自己没有要发送的消息了，并且收到了对方的确认消息

### 浏览器解析HTML

### 浏览器布局渲染



## http和https的区别？

http超文本传输协议是明文传输，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息

https是具有安全性的ssl加密传输协议，为浏览器和服务器之间的通信加密，确保数据传输的安全

https的加密方式分为对称加密和非对称加密。

其中对称加密时加密和解密用的是同一把密钥，在每次发送真实数据之前，服务器先生成一把密钥，然后先把密钥传给客户端，之后服务器在给服务端发送发送真实数据的时候，会用这把密钥对数据进行加密，客户端收到加密数据之后，用刚才收到的密钥进行解密

非对称加密算法需要两个密钥，公开密钥和私有密钥。公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密



http的连接是无状态的，而https是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议



http使用的端口是80，https使用的端口是443



http协议可以免费申请，而https协议需要申请到ca申请证书，一般需要缴费



## 什么是http的keep-alive机制?

在http1.0中，每次http请求都要创建一个http连接，而创建连接的过程需要消耗资源和时间，为了减少资源消耗，缩短响应时间，就需要重用连接。在后来的http1.1中是默认支持长连接的

http长连接会一直保持吗？肯定是不会的。一般服务端都会设置keep-alive超时时间，超过指定的时间间隔，服务端就会主动关闭连接。同时服务端还会设置一个参数叫最大请求数，比如当最大请求数是300时，只要请求次数超过300次，即使还没到超时时间，服务端也会主动关闭连接



# 运输层

## TCP

### TCP的ISN是如何选择的？

ISN(Initial Sequence Number)可以看作是一个32比特的计数器，每4ms加1。这样选择序号的目的在于防止网络中被延迟的分组在以后又被传送，而导致某个连接的一方对它作出错误的解释



### 为什么TCP需要三次握手？

在真正开始传输数据之前，客户端和服务器都需要确认以下条件：

自己的接收和发送是正常的 && 对方的接收和发送是正常的

也即通信双方必须确认彼此都有能力接并且响应

第一次，客户端向服务器发送一条请求连接报文被服务器正确接收后：

客户端：

| 自己 | 接收 | 发送 |
| :--: | :--: | :--: |
| 对方 | 接收 | 发送 |

服务器：知道自己的接收正常、对方的发送正常

| 自己 | 接收√ | 发送  |
| :--: | :---: | :---: |
| 对方 | 接收  | 发送√ |



第二次，服务器向客户端返回一条ACK消息，同意连接，被服务端正确接收后：

客户端：知道了自己的发送和接收是正常的，并且服务器的发送和接收是正常的

| 自己 | 接收√ | 发送√ |
| :--: | :---: | :---: |
| 对方 | 接收√ | 发送√ |

服务器：

| 自己 | 接收√ | 发送  |
| :--: | :---: | :---: |
| 对方 | 接收  | 发送√ |

第三次，客户端再向服务器发送ACK消息，服务器正确接收后：

客户端：

| 自己 | 接收√ | 发送√ |
| :--: | :---: | :---: |
| 对方 | 接收√ | 发送√ |

服务器：知道了自己的发送是正常的，对方的接收是正常的

| 自己 | 接收√ | 发送√ |
| :--: | :---: | :---: |
| 对方 | 接收√ | 发送√ |

至此通信双方都确认了自己和对方的发送和接收都是正常的，于是可以开始通信了。



第二个原因就是双方需要协商知道各自选择的序列号



### TCP的四次挥手

既然一个TCP连接是全双工（即数据在两个方向上能同时传递）的，因此每个方向必须单独地进行关闭。收到一个FIN只意味着在这一方向上没有数据流动。一个TCP连接在收到一个FIN后仍能发送数据，尽管大多数TCP应用都不会这么做。首先进行关闭的一方（即发送第一个FIN）将执行主动关闭，而另一方（收到这个FIN）执行被动关闭。通常一方完成主动关闭而另一方完成被动关闭，但还有一种情况就是双方都执行主动关闭。



#### TCP四次挥手的四个状态

![image-20201102205749273](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201102205749273.png)



#### 为什么TIME_WAIT要等待2MSL？

虽然对于客户端来说，自己发完最后一个ACK后就可以关闭socket了，这对于自己是没有任何影响的，但我们必须考虑到真实的网络是不可靠的，我们永远无法确定最后一个ACK到底到达了服务器没有。所以等待2MSL也是出于对服务器的保护，万一服务器没有收到最后一个ACK，它可以重新发送FIN报文给客户端，以便自己确认客户端收到了自己想要关闭连接的消息。MSL(Maximum Segment Lifetime)是报文在网络中最长的存活时间，理论上，如果服务端没有收到客户端最后一个ACK的话，其会重发FIN，客户端便会在2MSL时间内收到它重发的FIN，于是会再次发送ACK并重新计时



### 如果已经建立了连接，但是客户端突然出现了故障会如何？

许多TCP实现拥有一个保活计时器，尽管保活并不是TCP规范中的一部分，显然，客户端出现故障后，服务器不可能一直等待下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若2小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文段仍然没反应，服务器就认为客户端处理故障，接着就关闭连接



### 什么是TCP流量控制？

流量控制的本质是速度匹配服务，即发送方的发送速率和接收方的接收速率相匹配



### TCP流量控制是如何实现的？

TCP通过让发送方维护一个**接收窗口(receive window)**的变量来指示接收方还有多少可用的缓存空间，注意因为TCP是全双工通信，所以通信双方都会各自维护这样一个变量

记接收方的缓存大小为RcvBuffer

那么接收方应该满足以下条件：

LastByteRcvd - LastByteRead <= RcvBuffer

接收方当前可用的缓存大小为RcvBuffer - (LastByteRcvd - LastByteRead)，即rwnd

它把这个值作为回答报文发送给发送方

对于发送方，它受到接收方的rwnd后，应该试图满足以下条件：

LastByteSent - LastByteAcked <= rwnd

这样就可以保证接收方的缓存不会溢出



#### 上述实现的问题？

当接收方发送给发送方的rwnd大小为0的时候，发送方便不会再传输任何数据给接收方了，因为它不知道接收方或许已经有新的空间了。为了解决这个问题，TCP规范中要求：当接收方的rwnd为0时，发送方继续发送只有一个字节数据的报文段。这些报文段将会被接收方确认。最终缓存将开始清空，并且确认报文里将包含一个非0的rwnd值。



### 有哪些拥塞控制方法？

①端到端拥塞控制，TCP采用的就是这种拥塞控制方法，因为IP层不向端系统提供显式的拥塞反馈。

②网络辅助的拥塞控制，路由器向发送方提供关于网络拥塞状态的显式反馈信息。



### TCP发送方如何限制其发送速率？

通过设置一个**拥塞窗口**(congestion window)变量。在一个发送方中未被确认的数据量不会超过cwnd和rwnd(接收窗口)中的最小值，前者是为了满足拥塞控制，后者是为了满足流量控制。

即：LastByteSent - LastByteAcked <= min {cwnd, rwnd}



### TCP如何感知拥塞？

通常来讲，在传输过程中出现了丢包即可视为拥塞，丢包事件则被反映为：

Timeout事件 / 3次冗余的ACK



### 设计TCP拥塞算法的指导性原则？

①一个丢失的报文段意味着拥塞，因此当丢失报文段时应当降低TCP发送方的速率

②一个ACK报文段指示当前一切正常，可以增大发送速率

③TCP增加其速率以响应到达的ACK，除非出现丢包事件，才减小传输速率。因此，为了探测拥塞开始时出现的速率，TCP发送方增加它的传输速率，从该速率后退进而再次开始探测。



### TCP拥塞控制算法

#### 慢启动

TCP发送方希望迅速找到可用的带宽。在慢启动状态，发送方每接收到**一个**ACK就会将cwnd += MSS

因此，TCP发送速率起始慢，但在慢启动阶段以指数增长



##### 何时结束慢启动？

①当发送方遇到一个由timeout指示的丢包事件，TCP发送方将cwnd置为1并重新开始慢启动过程。它同时会维护一个ssthresh(慢启动阈值)的状态变量，将其设置为cwnd/2，即当检测到拥塞时将ssthresh设置为拥塞窗口大小的一半。当第二次慢启动（即**拥塞避免**状态）cwnd的值达到或超过ssthresh的值时，再使cwnd翻番似乎就不合适了，所以自此以后结束慢启动，进入**拥塞避免**模式。

②当发送方检测到3个冗余的ACK消息，这是TCP执行一种快速重传，并进入**快速恢复状态**



##### 为什么TCP对待Timeout与3次冗余的ACK采取的不同的解决方案？

这是因为从逻辑上讲，timeout似乎比3次冗余ACK更能体现出网络的拥塞，因为收到ACK说明虽然丢包了，但是至少通信的链路还是能够传递一些信息的（ACK消息），而timeout则说明通信链路连ACK消息都无法有效的传递了，所以直接将cwnd置为1.



#### 拥塞避免

一旦进入拥塞避免状态，cwnd的值大约是上次遇到拥塞时的值的一半，也就是说它离拥塞可能并不远了，所以采用比较保守的cwnd增长方法，即每收到一个cwnd的ACK才将cwnd += MSS，换句话说，就是cwnd += MSS * (MSS / cwnd)



#### 快速恢复（新特性）

在慢启动状态和拥塞避免状态中，如果遇到了dupACKcount == 3事件，则进入到快速恢复状态。将ssthresh设为cwnd的一半，然后cwnd = ssthresh + 3MSS

在快速恢复状态中，对于引起TCP进入快速恢复状态的丢失报文段，对收到的每个冗余的ACK，cwnd的值增加一个MSS（此阶段指数增长）。最终，当对丢失报文段的一个ACK到达时，TCP在降低cwnd至ssthresh后重返拥塞避免状态，开始线性增长

![image-20201013174711041](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201013174711041.png)



#### 为什么是dupACKcount == 3而不是别的数？

两次duplicate ACK肯定是乱序造成的

而丢包肯定会造成三次duplicate ACK



假定通信双方如下，A发送4个TCP Segment给B，编号如下，N-1成功到达，因为A收到B的ACK(N)

A方发送顺序：N-1, N, N+1, N+2

如果只是乱序了，B方到达顺序：

N-1, N, N+1, N+2    收到1个ACK(N)

N-1, N, N+2, N+1    收到1个ACK(N)

N-1, N+1, N, N+2    收到2个ACK(N)

N-1, N+1, N+2, N    收到3个ACK(N)

N-1, N+2, N, N+1    收到2个ACK(N)

N-1, N+2, N+1, N    收到3个ACK(N)



如果发生丢包了，没有到达B

N-1, N+1, N+2    收到3次ACK(N)

N-1, N+2, N-1     收到3次ACK(N)



#### 三种状态之间的FSM

![image-20201013175039298](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201013175039298.png)



#### 如何总结TCP的拥塞控制？

TCP拥塞控制常常被称为加性增、乘性减(Additive-Increase, Multiplicative-Decrease, AIMD)的拥塞控制方式。



### TCP是公平的吗？

是的

![image-20201013175706807](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201013175706807.png)

某条通信链路上面上维持了两个TCP连接。假如一开始在A点，这两条连接每过一个RTT都要将其窗口增加1个MSS，因此，这两条连接的总吞吐量就会从A点开始沿45°前行。直到它们的和超过了链路的容量，这时会发生丢包，两个连接就都会将其窗口减半，体现在图上就是由B点走向了C点。这样周而复始，则二者享用的带宽相等。



# 网络层

## 为什么运输层的TCP/UDP已经计算了校验和，网络层中的IP还要计算首部校验和呢？

首先，运输层中的TCP/UDP计算的是整个TCP/UDP报文段的校验和，而网络层中的IP计算的仅仅是IP首部的校验和，两者计算的范围不一样；其次，TCP/UDP与IP并不一定是紧紧耦合在一起的，即这两种协议并不一定属于同一个协议栈，事实上，TCP/UDP能够运行在一个不同的协议(如ATM)上，而IP也能够携带不一定要传递给TCP/UDP的数据



## 为什么RIP协议是由应用层的进程实现的，却被划分在网络层呢？

在计算机网络的层次中，某个协议处于第几层并不是由其具体的实现形式来决定的，而是由其具体实现的功能来决定的。并不是说网络层和下面的层必须由物理的形式来实现，它们也可以由应用进程来实现。所以路由器和其他的转发设备在计算机网络中最高只到网络层，但显然其也会运行更高层次的协议，只不过这些更高层次协议的全部目的都是为了实现网络层的功能



## NAT类型



## MAC地址和IP地址的区别？

MAC地址是“平面”地址：MAC地址可携带，在整个平面内都是唯一的，由IEEE进行分配，每个厂商在IEEE那里购买MAC地址的前24位(共48位). MAC地址属于数据链路层

IP地址是层次地址：IP地址不可携带，IP地址依赖于节点连接到哪个子网. IP地址属于网络层



# 数据链路层

## ARP协议

ARP(Address resolution protocal)地址解析协议解决的是这样一个问题：在同一个局域网内，如何在已知目的接口的IP地址前提下确定其MAC地址？

ARP表：LAN中**每个**IP节点(主机/路由器)维护的一个表，本质上是一个缓存。其存储某些LAN节点的IP/MAC映射关系<IP; MAC; TTL>

### ARP协议：同一局域网内

- A想要给同一局域网内的B发送数据报，而B的MAC地址不在Ａ的ARP表中
- A广播ARP查询分组，其中包含B的IP地址
  - 目的MAC地址: FF-FF-FF-FF-FF-FF
  - LAN中所有节点都会接收ARP查询
- B接收ARP查询分组，IP地址匹配成功，向A应答B的MAC地址
  - 利用单播帧向A发送应答
- A在其ARP表中，缓存B的IP-MAC地址对，直至超时
  - 超时时间通常设置为20min，超时后需要再次刷新
- ARP是“即插即用”协议
  - 节点自主创建ARP表，无需人工干预

### ARP协议：在不同局域网内

![image-20201226140504846](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201226140504846.png)

![image-20201226140522191](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201226140522191.png)

注意在整个过程中，源IP和目的IP是不变的，变化的是MAC地址。这也体现了计算机网络分层的特点

主机A首先找到其默认网关的IP地址，由这个IP地址找到网关的MAC地址，发送数据报

网关修改源MAC地址和目的MAC地址，做和A相同的事



## 什么是以太网？

以太网是一种被广泛采用的**局域网**技术



### 以太网拓扑结构

在上世纪90年代比较流行总线结构，这种结构的缺点是所有节点都处于同一个冲突域

目前的主流拓扑结构是星形结构，中心有一台中心交换机，每个节点一个单独冲突域，节点间彼此不冲突



## 什么是交换机？

交换机属于数据链路层设备，其功能位：

- 存储-转发以太网帧
- 检查到达帧的目的MAC地址，选择性向一个或多个输出链路转发帧
- 利用CSMA/CD访问链路，发送帧
- 主机感受不到交换机的存在

### 自学习

每个交换机有一个交换表，每个entry存储<主机MAC地址, 到达主机的接口, 时间戳>

交换机通过自学习，获知到达主机的接口信息

- 当收到帧时，交换机学习到发送帧的主机(通过帧的源MAC地址)，位于收到该帧的接口所连接的LAN网段
- 将发送主机MAC地址/接口信息记录到交换表中

当交换机收到帧：

- 记录帧的源MAC地址与输入链路接口

- 利用目的MAC地址检索交换表

- if 在交换表中检索到与目的MAC地址匹配的入口

- then {

  ​		if 目的主机位于收到帧的网段

  ​		then 丢弃帧

  ​		else 将帧转发到该入口指向的接口

- } else 泛洪 (向除收到该帧的接口之外的所有接口转发)

总结：目的MAC地址位置未知的话则泛洪，否则选择性转发



### 交换机互联

交换机之间也是可以互联的，它们之间交换消息也是通过自学习

![image-20201226220123720](C:\Users\liuwe\AppData\Roaming\Typora\typora-user-images\image-20201226220123720.png)

## 交换机和路由器的相似和区别？

两者均为存储-转发设备：

- 路由器是网络层设备，其检测网络层分组首部
- 交换机是链路层设备，其检测链路层帧的首部

二者均使用转发表：

- 路由器：利用路由算法(路由协议)计算并设置，依据IP地址
- 交换机：利用自学习、泛洪构建转发表，依据MAC地址

路由器隔离广播域，而交换机并不



![Image text](./Computer Networking Q&A.assets/binary_framing_layer01.svg)